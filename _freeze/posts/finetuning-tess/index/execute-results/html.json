{
  "hash": "da1e03c075fc55f489c756edfc4b87c8",
  "result": {
    "markdown": "---\ntitle: \"Fine-tuning Tesseract's OCR (with some help from R)\"\nauthor: \"Andrés Cruz\"\ndate: \"2023-01-02\"\ncategories: [R, tesseract, tesseractgt]\nimage: \"algae_sample.png\"\nabstract: \"Fine-tuning Tesseract's optical character recognition (OCR) to process a document with special characters, with the help of my new `tesseractgt` package.\"\n---\n\n\n## OCR with Tesseract\n\nLet's say that we need to OCR some non-standard text. For example, look at this extract from a 1893 book on algae:[^book]\n\n[^book]: Stokes, A. (1893). *Analytical keys to the genera and species of the fresh water Algae and the Desmidieae of the United States.* Portland, Conn.: Edward F. Bigelow. [Public domain, scanned by the Cornell University Library](https://archive.org/details/cu31924089431997).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example image for OCR.](algae_sample.png){#fig-example width=100%}\n:::\n:::\n\n\nWe can use the [Tesseract library](https://github.com/tesseract-ocr/tesseract), the premier open source OCR solution. Tesseract is conveniently wrapped in the `tesseract` R package:[^installation]\n\n[^installation]: See the package's [GitHub page](https://github.com/ropensci/tesseract) for installation instructions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tesseract)\nocr(\"algae_sample.png\", engine = tesseract(language = \"eng\")) |> cat()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n72. ZYGNEMA,\n\n§. Color soon becoming dark purple; filaments 20-25 in diam.,\n\npurpureum, 224\n§ Color green, or when in fruit yellowish or brownish (a).\na. Filaments with gelatinous sheath; cells 25 wide, anomalum, 224\na, “ 7 “ C cells 40-444 wide, crassum, 224\na. “ without sheath (4).\n&, Spore membrane smooth (¢).\nbf “ punctate or granulate (2).\n```\n:::\n:::\n\n\nPretty good! Fiddling with [image preprocessing](https://docs.ropensci.org/tesseract/articles/intro.html#preprocessing-with-magick) should get us even better results. But there's a bigger challenge here: the micron (µ) is not part of Tesseract's English character set. No matter how clean the input image is, off-the-self Tesseract will never detect those characters. This particular book is full of microns... what can we do?\n\n## Fine-tuning\n\nStarting in version 4, Tesseract uses a neural network for text detection. This means that we can re-train the model for our particular task! There are many ways to do so, from training a new language from scratch to fine-tuning an existing one.[^doctrain] Here we'll do the latter (which is easier to do and should yield better results in simple-ish cases like this one), using the English language (`eng`) as our base. I'll name my new \"language\" `alg` (this will be relevant for some later steps).\n\n[^doctrain]: See Tesseract's [training documentation](https://tesseract-ocr.github.io/tessdoc/tess5/TrainingTesseract-5.html) for more information.\n\n### Creating \"ground truth\" data\n\nFirst, we need some \"ground truth\" data for training. These should be image snippets from our document(s), with the corresponding text attached. There are [scripts](https://github.com/tesseract-ocr/tesstrain/issues/7) to generate all possible image snippets in a page. But here we are mostly interested in the microns and other special symbols, so I decided to simply take screenshots of possibly-important text. I took 52 screenshots from a couple of the other pages in the book (you can experiment with more), and threw them into a folder. This folder must be named `{language}-ground-truth/`, so I named it `alg-ground-truth/` (download it [here](alg-ground-truth.zip) to follow along). Here are a some of the screenshots:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A few of the 52 screenshots in the `alg-ground-truth/` folder. File names do not really matter (so you can just throw your raw screenshots in there if you want to).](imgs/screenshot_of_screenshots.png){#fig-screenshots width=80%}\n:::\n:::\n\n\nNow to the most time-consuming part. We need to make the text transcripts for these images. Tesseract expects files with the `gt.txt` extension, and the same name as the image. For the example above, we should have a `screenshot-001.gt.txt` file, containing the following text: \"less than 25µ (d).\" And a `screenshot-002.gt.txt` file, containing \"14-22µ\". And so on...\n\nMaking these files by hand gets old quickly, so I've made a little R package, [`tesseractgt`](https://github.com/arcruz0/tesseractgt), to speed things up. We first install it:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"remotes\") # only if `remotes` is not installed\nremotes::install_github(\"arcruz0/tesseractgt\")\n```\n:::\n\n\nA first step to save us time is to create boilerplate `.gt.txt` files automatically: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tesseractgt)\ncreate_gt_txt(folder = \"alg-ground-truth\", # folder with images \n              extension = \"png\",           # extension of image files\n              engine = tesseract::tesseract(language = \"eng\"))\n```\n:::\n\n\nThis creates all the needed `gt.txt` files:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![`alg-ground-truth/` folder with `gt.txt` files made by `create_gt_txt()`.](imgs/screenshots_with_text.png){#fig-screenshots-w-gt-txt width=80%}\n:::\n:::\n\n\nNote that the text files are already pre-filled with OCR text from `tesseract`, via the `engine = ` argument. These pre-fills will have problems (otherwise we wouldn't be fine-tuning!), but it is usually quicker to correct them than to write all text from scratch. You can also specify `engine = NULL` to generate empty `gt.txt` files.\n\nNow we need to correct these `gt.txt` files by hand. We can use a text editor, or the addin provided by `tesseractgt`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrect_gt_txt() # or \"Addins > Correct ground truth files\" in RStudio\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Manually correcting the ground-truth files with `correct_gt_txt()`.](imgs/addin.gif){#fig-addin width=70%}\n:::\n:::\n\n\nAnd that's it! We can now use the `alg-ground-truth/` folder to fine-tune the neural network.\n\n### Running the fine-tuning\n\nHere we will use the [`tesstrain` GitHub repository](https://github.com/tesseract-ocr/tesstrain), by the Tesseract developers. The procedure should work on Unix systems.[^os] On Ubuntu 22.04 (LTS), I did not have to install anything on top of Tesseract (but check the previous link if you have any issues with dependencies). We start by cloning the repository from our console (you can also download the zipped folder from GitHub):\n\n[^os]: On Windows, the safest choice is probably to use the [Windows Subsystem for Linux (WSL)](https://learn.microsoft.com/en-us/windows/wsl/install).\n\n\n::: {.cell}\n\n```{.sh .cell-code}\ngit clone https://github.com/tesseract-ocr/tesstrain.git\n```\n:::\n\n\nWe first go to our new `tesstrain/` folder and set up some configuration files:\n\n\n::: {.cell}\n\n```{.sh .cell-code}\ncd tesstrain # wherever you saved this folder \nmake tesseract-langdata\n```\n:::\n\n\nWe now move our previously-created `alg-ground-truth/` folder to `tesstrain/data/`. If we want to, we can use the command line from the `tesstrain/` folder:\n\n\n::: {.cell}\n\n```{.sh .cell-code}\nmv ~/location/alg-ground-truth data # should replace ~/location\n```\n:::\n\n\nNow we need to obtain the base language for training, which would be English in our case. We start by downloading the `eng.traineddata` file from the [`tessdata_best` GitHub repository](https://github.com/tesseract-ocr/tessdata_best).[^best] We need to place this file in the `tesstrain` folder, in a `usr/share/tessdata/` subfolder. If we want to, we can use the command line to create the subfolder and download the file from GitHub (change `eng` with your base language if needed):\n\n[^best]: The procedure will only work with these \"best\" `{language}.traineddata` files, so don't try to use any of the lighter ones.\n\n\n::: {.cell}\n\n```{.sh .cell-code}\nmkdir -p usr/share/tessdata\nwget -P usr/share/tessdata https://github.com/tesseract-ocr/tessdata_best/raw/main/eng.traineddata\n```\n:::\n\n\nAt this point, our `tesstrain/` folder should look like this:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n├── generate_gt_from_box.py; generate_line_box.py; generate_line_syllable_box.py; \n├── generate_wordstr_box.py; normalize.py; shuffle.py\n├── README.md; LICENSE; Makefile; requirements.txt; ocrd-testset.zip\n├── data/\n│   ├── alg-ground-truth/\n│   │   ├── screenshot-001.gt.txt\n│   │   ├── screenshot-001.png\n│   │   ├── screenshot-002.gt.txt\n│   │   ├── screenshot-002.png\n│   │   ├── (etc)\n│   └── langdata/\n│       ├── Arabic.unicharset\n│       ├── Armenian.unicharset\n│       ├── (etc)\n├── plot/\n│   ├── plot_cer.py\n│   └── plot_cer_validation.py\n├── src/\n│   └── training/\n│       ├── language_specific.py\n│       ├── tesstrain.py\n│       └── tesstrain_utils.py\n└── usr/\n    └── share/\n        └── tessdata/\n            └── eng.traineddata\n```\n:::\n:::\n\n\nFinally, we can fine-tune! The command below will provide sensible defaults for us, fine-tuning in the \"Impact\" mode.[^mode] In order to modify the fine-tuning hyperparameters (for example, setting a different learning rate or data splitting ratio), consult the [`tesstrain` documentation](https://github.com/tesseract-ocr/tesstrain) and modify the command below.\n\n[^mode]: There are other modes, but in my limited testing, this one provides good results quickly. Check out the [`tesstrain` documentation](https://github.com/tesseract-ocr/tesstrain) for more options.\n\n\n::: {.cell}\n\n```{.sh .cell-code}\nmake training MODEL_NAME=alg START_MODEL=eng FINETUNE_TYPE=Impact\n```\n:::\n\n\nFor our example with 52 \"ground truth\" images, the fine-tuning only took a couple of minutes to run on my laptop. \n\nThe command should have created a file named `data/alg.traineddata`, with our new fine-tuned model. We now need to get this to our system-wide folder of installed Tesseract languages. We can use R to find out where this folder is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntesseract::tesseract_info()$datapath # my output is specific to Linux\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"/usr/share/tesseract-ocr/5/tessdata/\"\n```\n:::\n:::\n\n\nAnd we simply copy-paste our `.traineddata` file to this folder. Using the command line:\n\n\n::: {.cell}\n\n```{.sh .cell-code}\nsudo cp data/alg.traineddata /usr/share/tesseract-ocr/5/tessdata/\n```\n:::\n\n\nThat's it, we're done with fine-tuning! We can now use Tesseract as usual for whatever task we are interested in, with our new \"alg\" language already available. You can check the available languages from R, with `tesseract::tesseract_info()$available`.\n\n## Results\n\nBelow we have the original image, and then our initial and refined OCR results side by side.\n\n![](algae_sample.png)\n\n::: {.column-screen-inset}\n\n::: {layout-ncol=2}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nocr(\"algae_sample.png\", engine = tesseract(language = \"eng\")) |> cat()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n72. ZYGNEMA,\n\n§. Color soon becoming dark purple; filaments 20-25 in diam.,\n\npurpureum, 224\n§ Color green, or when in fruit yellowish or brownish (a).\na. Filaments with gelatinous sheath; cells 25 wide, anomalum, 224\na, “ 7 “ C cells 40-444 wide, crassum, 224\na. “ without sheath (4).\n&, Spore membrane smooth (¢).\nbf “ punctate or granulate (2).\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nocr(\"algae_sample.png\", engine = tesseract(language = \"alg\")) |> cat()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n72. ZYGNEMA.\n\n§. Color soon becoming dark purple; filaments 20-25µ in diam.,\n\npurpureum, 224\n§ Color green, or when in fruit yellowish or brownish (a).\na. Filaments with gelatinous sheath; cells 25µ wide, anomalum, 224\na. \" & \" L cells 40-44µ wide, crassum, 224\na. \" without sheath (b).\nb. Spore membrane smooth (c).\nbL \" \" punctate or granulate (d).\n```\n:::\n:::\n\n\n:::\n\n:::\n\nWe got the microns! We also had some other minor improvements in the last couple of lines, possibly due to supplying the model with more examples of the specific typography. There are still some errors, that we might be able to solve with more aggressive fine-tuning, or with ex-post corrections. In any case, I hope that this blog post and `tesseractgt` are useful!\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}