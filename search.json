[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Fine-tuning Tesseract’s OCR (with some help from R)\n\n\n\n\n\n\n\nR\n\n\ntesseract\n\n\ntesseractgt\n\n\n\n\nFine-tuning Tesseract’s optical character recognition (OCR) to process a document with special characters, with the help of my new tesseractgt package.\n\n\n\n\n\n\nJan 2, 2023\n\n\nAndrés Cruz\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andrés Cruz",
    "section": "",
    "text": "Hi! I am a graduate student at UT Austin, where I am pursuing a PhD in Government and an MS in Statistics. I am broadly interested in computational social science and applications in comparative politics.\nPreviously, I was a full-time RA on a household finance project led by Erik Berwart (CMF), Sean Higgins (Northwestern), Sheisha Kulkarni (UVa), and Santiago Truffa (UAndes). I received a BA and MA in Political Science from Pontificia Universidad Católica de Chile."
  },
  {
    "objectID": "posts/finetuning-tess/index.html",
    "href": "posts/finetuning-tess/index.html",
    "title": "Fine-tuning Tesseract’s OCR (with some help from R)",
    "section": "",
    "text": "Let’s say that we need to OCR some non-standard text. For example, look at this extract from a 1893 book on algae:1\n\n\n\n\n\nFigure 1: Example image for OCR.\n\n\n\n\nWe can use the Tesseract library, the premier open source OCR solution. Tesseract is conveniently wrapped in the tesseract R package:2\n\nlibrary(tesseract)\nocr(\"algae_sample.png\", engine = tesseract(language = \"eng\")) |&gt; cat()\n\n72. ZYGNEMA,\n\n§. Color soon becoming dark purple; filaments 20-25 in diam.,\n\npurpureum, 224\n§ Color green, or when in fruit yellowish or brownish (a).\na. Filaments with gelatinous sheath; cells 25 wide, anomalum, 224\na, “ 7 “ C cells 40-444 wide, crassum, 224\na. “ without sheath (4).\n&, Spore membrane smooth (¢).\nbf “ punctate or granulate (2).\n\n\nPretty good! Fiddling with image preprocessing should get us even better results. But there’s a bigger challenge here: the micron (µ) is not part of Tesseract’s English character set. No matter how clean the input image is, off-the-self Tesseract will never detect those characters. This particular book is full of microns… what can we do?"
  },
  {
    "objectID": "posts/finetuning-tess/index.html#ocr-with-tesseract",
    "href": "posts/finetuning-tess/index.html#ocr-with-tesseract",
    "title": "Fine-tuning Tesseract’s OCR (with some help from R)",
    "section": "",
    "text": "Let’s say that we need to OCR some non-standard text. For example, look at this extract from a 1893 book on algae:1\n\n\n\n\n\nFigure 1: Example image for OCR.\n\n\n\n\nWe can use the Tesseract library, the premier open source OCR solution. Tesseract is conveniently wrapped in the tesseract R package:2\n\nlibrary(tesseract)\nocr(\"algae_sample.png\", engine = tesseract(language = \"eng\")) |&gt; cat()\n\n72. ZYGNEMA,\n\n§. Color soon becoming dark purple; filaments 20-25 in diam.,\n\npurpureum, 224\n§ Color green, or when in fruit yellowish or brownish (a).\na. Filaments with gelatinous sheath; cells 25 wide, anomalum, 224\na, “ 7 “ C cells 40-444 wide, crassum, 224\na. “ without sheath (4).\n&, Spore membrane smooth (¢).\nbf “ punctate or granulate (2).\n\n\nPretty good! Fiddling with image preprocessing should get us even better results. But there’s a bigger challenge here: the micron (µ) is not part of Tesseract’s English character set. No matter how clean the input image is, off-the-self Tesseract will never detect those characters. This particular book is full of microns… what can we do?"
  },
  {
    "objectID": "posts/finetuning-tess/index.html#fine-tuning",
    "href": "posts/finetuning-tess/index.html#fine-tuning",
    "title": "Fine-tuning Tesseract’s OCR (with some help from R)",
    "section": "Fine-tuning",
    "text": "Fine-tuning\nStarting in version 4, Tesseract uses a neural network for text detection. This means that we can re-train the model for our particular task! There are many ways to do so, from training a new language from scratch to fine-tuning an existing one.3 Here we’ll do the latter (which is easier to do and should yield better results in simple-ish cases like this one), using the English language (eng) as our base. I’ll name my new “language” alg (this will be relevant for some later steps).\n\nCreating “ground truth” data\nFirst, we need some “ground truth” data for training. These should be image snippets from our document(s), with the corresponding text attached. There are scripts to generate all possible image snippets in a page. But here we are mostly interested in the microns and other special symbols, so I decided to simply take screenshots of possibly-important text. I took 52 screenshots from a couple of the other pages in the book (you can experiment with more), and threw them into a folder. This folder must be named {language}-ground-truth/, so I named it alg-ground-truth/ (download it here to follow along). Here are a some of the screenshots:\n\n\n\n\n\nFigure 2: A few of the 52 screenshots in the alg-ground-truth/ folder. File names do not really matter (so you can just throw your raw screenshots in there if you want to).\n\n\n\n\nNow to the most time-consuming part. We need to make the text transcripts for these images. Tesseract expects files with the gt.txt extension, and the same name as the image. For the example above, we should have a screenshot-001.gt.txt file, containing the following text: “less than 25µ (d).” And a screenshot-002.gt.txt file, containing “14-22µ”. And so on…\nMaking these files by hand gets old quickly, so I’ve made a little R package, tesseractgt, to speed things up. We first install it:\n\ninstall.packages(\"remotes\") # only if `remotes` is not installed\nremotes::install_github(\"arcruz0/tesseractgt\")\n\nA first step to save us time is to create boilerplate .gt.txt files automatically:\n\nlibrary(tesseractgt)\ncreate_gt_txt(folder = \"alg-ground-truth\", # folder with images \n              extension = \"png\",           # extension of image files\n              engine = tesseract::tesseract(language = \"eng\"))\n\nThis creates all the needed gt.txt files:\n\n\n\n\n\nFigure 3: alg-ground-truth/ folder with gt.txt files made by create_gt_txt().\n\n\n\n\nNote that the text files are already pre-filled with OCR text from tesseract, via the engine = argument. These pre-fills will have problems (otherwise we wouldn’t be fine-tuning!), but it is usually quicker to correct them than to write all text from scratch. You can also specify engine = NULL to generate empty gt.txt files.\nNow we need to correct these gt.txt files by hand. We can use a text editor, or the addin provided by tesseractgt:\n\ncorrect_gt_txt() # or \"Addins &gt; Correct ground truth files\" in RStudio\n\n\n\n\n\n\nFigure 4: Manually correcting the ground-truth files with correct_gt_txt().\n\n\n\n\nAnd that’s it! We can now use the alg-ground-truth/ folder to fine-tune the neural network.\n\n\nRunning the fine-tuning\nHere we will use the tesstrain GitHub repository, by the Tesseract developers. The procedure should work on Unix systems.4 On Ubuntu 22.04 (LTS), I did not have to install anything on top of Tesseract (but check the previous link if you have any issues with dependencies). We start by cloning the repository from our console (you can also download the zipped folder from GitHub):\n\ngit clone https://github.com/tesseract-ocr/tesstrain.git\n\nWe first go to our new tesstrain/ folder and set up some configuration files:\n\ncd tesstrain # wherever you saved this folder \nmake tesseract-langdata\n\nWe now move our previously-created alg-ground-truth/ folder to tesstrain/data/. If we want to, we can use the command line from the tesstrain/ folder:\n\nmv ~/location/alg-ground-truth data # should replace ~/location\n\nNow we need to obtain the base language for training, which would be English in our case. We start by downloading the eng.traineddata file from the tessdata_best GitHub repository.5 We need to place this file in the tesstrain folder, in a usr/share/tessdata/ subfolder. If we want to, we can use the command line to create the subfolder and download the file from GitHub (change eng with your base language if needed):\n\nmkdir -p usr/share/tessdata\nwget -P usr/share/tessdata https://github.com/tesseract-ocr/tessdata_best/raw/main/eng.traineddata\n\nAt this point, our tesstrain/ folder should look like this:\n\n\n├── generate_gt_from_box.py; generate_line_box.py; generate_line_syllable_box.py; \n├── generate_wordstr_box.py; normalize.py; shuffle.py\n├── README.md; LICENSE; Makefile; requirements.txt; ocrd-testset.zip\n├── data/\n│   ├── alg-ground-truth/\n│   │   ├── screenshot-001.gt.txt\n│   │   ├── screenshot-001.png\n│   │   ├── screenshot-002.gt.txt\n│   │   ├── screenshot-002.png\n│   │   ├── (etc)\n│   └── langdata/\n│       ├── Arabic.unicharset\n│       ├── Armenian.unicharset\n│       ├── (etc)\n├── plot/\n│   ├── plot_cer.py\n│   └── plot_cer_validation.py\n├── src/\n│   └── training/\n│       ├── language_specific.py\n│       ├── tesstrain.py\n│       └── tesstrain_utils.py\n└── usr/\n    └── share/\n        └── tessdata/\n            └── eng.traineddata\n\n\nFinally, we can fine-tune! The command below will provide sensible defaults for us, fine-tuning in the “Impact” mode.6 In order to modify the fine-tuning hyperparameters (for example, setting a different learning rate or data splitting ratio), consult the tesstrain documentation and modify the command below.\n\nmake training MODEL_NAME=alg START_MODEL=eng FINETUNE_TYPE=Impact\n\nFor our example with 52 “ground truth” images, the fine-tuning only took a couple of minutes to run on my laptop.\nThe command should have created a file named data/alg.traineddata, with our new fine-tuned model. We now need to get this to our system-wide folder of installed Tesseract languages. We can use R to find out where this folder is:\n\ntesseract::tesseract_info()$datapath # my output is specific to Linux\n\n[1] \"/usr/share/tesseract-ocr/5/tessdata/\"\n\n\nAnd we simply copy-paste our .traineddata file to this folder. Using the command line:\n\nsudo cp data/alg.traineddata /usr/share/tesseract-ocr/5/tessdata/\n\nThat’s it, we’re done with fine-tuning! We can now use Tesseract as usual for whatever task we are interested in, with our new “alg” language already available. You can check the available languages from R, with tesseract::tesseract_info()$available."
  },
  {
    "objectID": "posts/finetuning-tess/index.html#results",
    "href": "posts/finetuning-tess/index.html#results",
    "title": "Fine-tuning Tesseract’s OCR (with some help from R)",
    "section": "Results",
    "text": "Results\nBelow we have the original image, and then our initial and refined OCR results side by side.\n\n\n\n\n\nocr(\"algae_sample.png\", engine = tesseract(language = \"eng\")) |&gt; cat()\n\n72. ZYGNEMA,\n\n§. Color soon becoming dark purple; filaments 20-25 in diam.,\n\npurpureum, 224\n§ Color green, or when in fruit yellowish or brownish (a).\na. Filaments with gelatinous sheath; cells 25 wide, anomalum, 224\na, “ 7 “ C cells 40-444 wide, crassum, 224\na. “ without sheath (4).\n&, Spore membrane smooth (¢).\nbf “ punctate or granulate (2).\n\n\n\nocr(\"algae_sample.png\", engine = tesseract(language = \"alg\")) |&gt; cat()\n\n72. ZYGNEMA.\n\n§. Color soon becoming dark purple; filaments 20-25µ in diam.,\n\npurpureum, 224\n§ Color green, or when in fruit yellowish or brownish (a).\na. Filaments with gelatinous sheath; cells 25µ wide, anomalum, 224\na. \" & \" L cells 40-44µ wide, crassum, 224\na. \" without sheath (b).\nb. Spore membrane smooth (c).\nbL \" \" punctate or granulate (d).\n\n\n\n\n\nWe got the microns! We also had some other minor improvements in the last couple of lines, possibly due to supplying the model with more examples of the specific typography. There are still some errors, that we might be able to solve with more aggressive fine-tuning, or with ex-post corrections. In any case, I hope that this blog post and tesseractgt are useful!"
  },
  {
    "objectID": "posts/finetuning-tess/index.html#footnotes",
    "href": "posts/finetuning-tess/index.html#footnotes",
    "title": "Fine-tuning Tesseract’s OCR (with some help from R)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nStokes, A. (1893). Analytical keys to the genera and species of the fresh water Algae and the Desmidieae of the United States. Portland, Conn.: Edward F. Bigelow. Public domain, scanned by the Cornell University Library.↩︎\nSee the package’s GitHub page for installation instructions.↩︎\nSee Tesseract’s training documentation for more information.↩︎\nOn Windows, the safest choice is probably to use the Windows Subsystem for Linux (WSL).↩︎\nThe procedure will only work with these “best” {language}.traineddata files, so don’t try to use any of the lighter ones.↩︎\nThere are other modes, but in my limited testing, this one provides good results quickly. Check out the tesstrain documentation for more options.↩︎"
  },
  {
    "objectID": "r_resources.html",
    "href": "r_resources.html",
    "title": "R Resources",
    "section": "",
    "text": "Textbook: R for Political Data Science / AnalizaR Datos Políticos\nCo-edited with Francisco Urdinez\nA textbook that introduces R and the tidyverse from scratch using examples from Latin American political science.\n\n\n\nCourse: Programming for the Social Sciences\nFrom 2019 to 2021 I taught a computational social science class for undergraduate students at UDP and PUC. The link above has class materials for the 2020 edition at PUC (in Spanish).\n\n\n\nR package: inexact\n\n\n\n\n\n\n\n\n\nA package to supervise fuzzy joins, i.e. a tool for dealing with non-standardized ID variables when joining data sets. See my slides for the Toronto Workshop on Reproducibility.\n\n\n\nR package: tesseractgt\n\n\n\n\n\n\n\n\n\nA package to generate “ground truth” data for retraining or fine-tuning Tesseract’s optical character recognition (OCR) neural network. See the blog post."
  },
  {
    "objectID": "workshops/speedyr.html",
    "href": "workshops/speedyr.html",
    "title": "Speedy R: loops, parallelization, and the cloud",
    "section": "",
    "text": "[Slides]\n[.R script]"
  }
]